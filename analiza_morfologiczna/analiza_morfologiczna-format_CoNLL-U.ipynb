{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przetwarzania plików CoNLL-U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W formacie CoNLL-U każdemu segmentowi odpowiada 1 linia, która składa się z kolumn:\n",
    "\n",
    "    ID: numer kolejny słowa w zdaniu,\n",
    "    ORTH: forma tekstowa,\n",
    "    LEMMA: lemat,\n",
    "    UPOS: uniwersalna część mowy,\n",
    "    XPOS: tag właściwy dla danego języka,\n",
    "    UFEATS: uniwersalne cechy morfologiczne,\n",
    "    HEAD: id nadrzędnika,\n",
    "    DEPREL: etykieta relacji zależnościowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na potrzeby tej lekcji utorzymy 2 foldery\n",
    "import os\n",
    "os.makedirs(r'nlp_task/source', exist_ok=True)\n",
    "os.makedirs(r'nlp_task/predictions', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pl_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Kupiliśmy nowy samochód.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podstawowy moduł nie rozdzieli słowa \"kupiliśmy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEGMENT              LEMAT                UPOS                \n",
      "Kupiliśmy            kupić                VERB                \n",
      "nowy                 nowy                 ADJ                 \n",
      "samochód             samochód             NOUN                \n",
      ".                    .                    PUNCT               \n"
     ]
    }
   ],
   "source": [
    "print(\"{:20} {:20} {:20}\".format('SEGMENT', 'LEMAT', 'UPOS'))\n",
    "for token in doc:\n",
    "    print(\"{:20} {:20} {:20}\".format(token.text, token.lemma_, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install spacy-conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteka spacy_conll służy do przetwarzania wstępnie posegmentowanych plików. \n",
    "# Funkcja init_parser posiada argument is_tokenized (True = nie należy przeprowadzać segmentacji)\n",
    "from spacy_conll import init_parser\n",
    "nlp = init_parser('spacy', 'pl_core_news_sm', is_tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Kupili śmy nowy samochód .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEGMENT              LEMAT                UPOS                \n",
      "Kupili               kupić                VERB                \n",
      "śmy                  być                  AUX                 \n",
      "nowy                 nowy                 ADJ                 \n",
      "samochód             samochód             NOUN                \n",
      ".                    .                    PUNCT               \n"
     ]
    }
   ],
   "source": [
    "print(\"{:20} {:20} {:20}\".format('SEGMENT', 'LEMAT', 'UPOS'))\n",
    "for token in doc:\n",
    "    print(\"{:20} {:20} {:20}\".format(token.text, token.lemma_, token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetwarzanie stringa i zapisywanie wyniku do pliku przy pomocy wiersza poleceń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!parse-as-conll --model_or_lang 'pl_core_news_sm' --input_str 'Kupiliśmy nowy samochód.' --output_file 'file_1.conllu' --include_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sent_id = 1\r\n",
      "# text = Kupiliśmy nowy samochód.\r\n",
      "1\tKupiliśmy\tkupić\tVERB\tPRAET\t_\t0\tROOT\t_\t_\r\n",
      "2\tnowy\tnowy\tADJ\tADJ\t_\t3\tamod\t_\t_\r\n",
      "3\tsamochód\tsamochód\tNOUN\tSUBST\t_\t1\tobj\t_\tSpaceAfter=No\r\n",
      "4\t.\t.\tPUNCT\tINTERP\t_\t1\tpunct\t_\tSpaceAfter=No\r\n"
     ]
    }
   ],
   "source": [
    "! head file_1.conllu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobierz plik txt i zapisz go do folderu \"source\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-02 12:39:40--  https://wolnelektury.pl/media/book/txt/korczak-krol-macius-na-wyspie-bezludnej.txt\n",
      "Resolving wolnelektury.pl (wolnelektury.pl)... 51.83.143.148, 2001:41d0:602:3294::\n",
      "Connecting to wolnelektury.pl (wolnelektury.pl)|51.83.143.148|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 326911 (319K) [text/plain]\n",
      "Saving to: ‘nlp_task/source/korczak-krol-macius-na-wyspie-bezludnej.txt’\n",
      "\n",
      "korczak-krol-macius 100%[===================>] 319,25K  --.-KB/s    in 0,09s   \n",
      "\n",
      "2021-01-02 12:39:40 (3,55 MB/s) - ‘nlp_task/source/korczak-krol-macius-na-wyspie-bezludnej.txt’ saved [326911/326911]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P nlp_task/source https://wolnelektury.pl/media/book/txt/korczak-krol-macius-na-wyspie-bezludnej.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Janusz Korczak\r",
      "\r\n",
      "\r",
      "\r\n",
      "Król Maciuś na wyspie bezludnej\r",
      "\r\n",
      "\r",
      "\r\n",
      "ISBN 978-83-288-2376-1\r",
      "\r\n",
      "\r",
      "\r\n",
      "\r",
      "\r\n",
      "Ach, jak strasznie źle było Maciusiowi w więzieniu. Właściwie nie było mu źle — ale ciasno. Ciasno i nudno.\r",
      "\r\n",
      "\r",
      "\r\n",
      "Bo jeżeli ktoś siedzi w więzieniu — i mają rozstrzelać — wcale się nie nudzi. Ale Maciuś miał być wysłany na bezludną wyspę. Maciuś przegrał wojnę, był jeńcem królewskim i — zupełnie jak Napoleon będzie wysłany na wyspę.\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 nlp_task/source/korczak-krol-macius-na-wyspie-bezludnej.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t1m1,877s\r\n",
      "user\t0m57,427s\r\n",
      "sys\t0m4,907s\r\n"
     ]
    }
   ],
   "source": [
    "! time parse-as-conll --model_or_lang 'pl_core_news_sm' --input_file 'nlp_task/source/korczak-krol-macius-na-wyspie-bezludnej.txt' --output_file 'nlp_task/predictions/file.conllu' --include_headers\n",
    "# real = czas w którym przetworzone zostało 5470 zdań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tPraw\tprawo\tNOUN\tSUBST\t_\t5\tnmod\t_\t_\r\n",
      "7\tDziecka\tdziecko\tNOUN\tSUBST\t_\t6\tnmod\t_\tSpaceAfter=No\r\n",
      "8\t.\t.\tPUNCT\tINTERP\t_\t2\tpunct\t_\t_\r\n",
      "\r\n",
      "# sent_id = 5468\r\n",
      "# text = Reprodukcja cyfrowa wykonana przez Fundację Nowoczesna Polska.\r\n",
      "1\tReprodukcja\treprodukcja\tNOUN\tSUBST\t_\t3\tnsubj\t_\t_\r\n",
      "2\tcyfrowa\tcyfrowy\tADJ\tADJ\t_\t1\tamod\t_\t_\r\n",
      "3\twykonana\twykonać\tVERB\tPPAS\t_\t0\tROOT\t_\t_\r\n",
      "4\tprzez\tprzez\tADP\tPREP\t_\t5\tcase\t_\t_\r\n",
      "5\tFundację\tfundacja\tNOUN\tSUBST\t_\t3\tobl:arg\t_\t_\r\n",
      "6\tNowoczesna\tnowoczesny\tADJ\tADJ\t_\t5\tnmod\t_\t_\r\n",
      "7\tPolska\tpolska\tNOUN\tSUBST\t_\t5\tamod\t_\tSpaceAfter=No\r\n",
      "8\t.\t.\tPUNCT\tINTERP\t_\t3\tpunct\t_\tSpaceAfter=No\r\n",
      "\r\n",
      "# sent_id = 5469\r\n",
      "# text = Opracowanie redakcyjne i przypisy: Paulina Choromańska, Agnieszka Gąsior, Wojciech Kotwica, Dorota Kowalska, Paweł Kozioł.\r\n",
      "1\tOpracowanie\topracowanie\tNOUN\tSUBST\t_\t5\tnsubj\t_\t_\r\n",
      "2\tredakcyjne\tredakcyjny\tADJ\tADJ\t_\t1\tamod\t_\t_\r\n",
      "3\ti\ti\tCCONJ\tCONJ\t_\t4\tcc\t_\t_\r\n",
      "4\tprzypisy\tprzypis\tNOUN\tSUBST\t_\t2\tconj\t_\tSpaceAfter=No\r\n",
      "5\t:\t:\tPUNCT\tINTERP\t_\t0\tROOT\t_\t_\r\n",
      "6\tPaulina\tpaulin\tNOUN\tSUBST\t_\t5\tnmod\t_\t_\r\n",
      "7\tChoromańska\tchoromańska\tNOUN\tSUBST\t_\t6\tnmod\t_\tSpaceAfter=No\r\n",
      "8\t,\t,\tPUNCT\tINTERP\t_\t9\tpunct\t_\t_\r\n",
      "9\tAgnieszka\tagnieszka\tNOUN\tSUBST\t_\t5\tappos\t_\t_\r\n",
      "10\tGąsior\tGąsiory\tNOUN\tSUBST\t_\t9\tnmod\t_\tSpaceAfter=No\r\n",
      "11\t,\t,\tPUNCT\tINTERP\t_\t12\tpunct\t_\t_\r\n",
      "12\tWojciech\tWojciechy\tNOUN\tSUBST\t_\t9\tappos\t_\t_\r\n",
      "13\tKotwica\tkotwica\tNOUN\tSUBST\t_\t12\tnmod\t_\tSpaceAfter=No\r\n",
      "14\t,\t,\tPUNCT\tINTERP\t_\t15\tpunct\t_\t_\r\n",
      "15\tDorota\tdorota\tNOUN\tSUBST\t_\t5\tappos\t_\t_\r\n",
      "16\tKowalska\tkowalska\tNOUN\tSUBST\t_\t15\tappos\t_\tSpaceAfter=No\r\n",
      "17\t,\t,\tPUNCT\tINTERP\t_\t18\tpunct\t_\t_\r\n",
      "18\tPaweł\tPawła\tNOUN\tSUBST\t_\t5\tconj\t_\t_\r\n",
      "19\tKozioł\tkozioł\tNOUN\tSUBST\t_\t18\tnmod\t_\tSpaceAfter=No\r\n",
      "20\t.\t.\tPUNCT\tINTERP\t_\t5\tpunct\t_\tSpaceAfter=No\r\n",
      "\r\n",
      "# sent_id = 5470\r\n",
      "# text = ISBN 978-83-288-2376-1\r\n",
      "1\tISBN\tisbn\tADJ\tADJ\t_\t0\tROOT\t_\t_\r\n",
      "2\t978\t978\tNUM\tNUM\t_\t3\tdep\t_\tSpaceAfter=No\r\n",
      "3\t-\t-\tPUNCT\tINTERP\t_\t4\tdep\t_\tSpaceAfter=No\r\n",
      "4\t83\t83\tNUM\tNUM\t_\t5\tdep\t_\tSpaceAfter=No\r\n",
      "5\t-\t-\tPUNCT\tINTERP\t_\t6\tdep\t_\tSpaceAfter=No\r\n",
      "6\t288\t288\tNUM\tNUM\t_\t7\tdep\t_\tSpaceAfter=No\r\n",
      "7\t-\t-\tPUNCT\tINTERP\t_\t8\tdep\t_\tSpaceAfter=No\r\n",
      "8\t2376\t2376\tNUM\tNUM\t_\t9\tdep\t_\tSpaceAfter=No\r\n",
      "9\t-\t-\tPUNCT\tINTERP\t_\t10\tdep\t_\tSpaceAfter=No\r\n",
      "10\t1\t1\tADJ\tADJ\t_\t1\tamod\t_\tSpaceAfter=No\r\n"
     ]
    }
   ],
   "source": [
    "# zdania oddzielane są pustą linią, sent_id = numer zdania. text = treść zdania\n",
    "! tail -n 50 nlp_task/predictions/file.conllu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
